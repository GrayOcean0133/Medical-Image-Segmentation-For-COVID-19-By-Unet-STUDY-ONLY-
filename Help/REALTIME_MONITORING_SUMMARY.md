# å®æ—¶è®­ç»ƒç›‘æ§ç³»ç»Ÿ - å®Œæ•´å‡çº§æŠ¥å‘Š

## æ–°å¢åŠŸèƒ½æ€»è§ˆ

æˆ‘å·²ç»ä¸ºä½ çš„è®­ç»ƒç³»ç»Ÿæ·»åŠ äº†**å®Œæ•´çš„å®æ—¶ç›‘æ§å’Œæ•°æ®è®°å½•åŠŸèƒ½**ï¼Œè®©ä½ å¯ä»¥ï¼š

âœ… **å®æ—¶æŸ¥çœ‹** æ¯ä¸ªbatchå’Œepochçš„losså˜åŒ–
âœ… **è‡ªåŠ¨ä¿å­˜** æ‰€æœ‰è®­ç»ƒæŒ‡æ ‡åˆ°CSVæ–‡ä»¶
âœ… **äº‹ååˆ†æ** ä½¿ç”¨å¯è§†åŒ–å·¥å…·å¤ç›˜è®­ç»ƒè¿‡ç¨‹
âœ… **çµæ´»é…ç½®** è®°å½•ç²’åº¦å’Œè¾“å‡ºé¢‘ç‡

---

## ä¸€ã€æ–°å¢çš„ç›‘æ§æ•°æ®

### å®æ—¶æ˜¾ç¤ºï¼ˆè®­ç»ƒè¿‡ç¨‹ä¸­ï¼‰

```
Epoch [15/200] - è¿›åº¦ 5.8% (10/171) - Batch Loss: 0.078203 - LR: 0.00100000
Epoch [15/200] - è¿›åº¦ 11.7% (20/171) - Batch Loss: 0.072156 - LR: 0.00100000
Epoch [15/200] - è¿›åº¦ 17.5% (30/171) - Batch Loss: 0.069234 - LR: 0.00100000
...
```

**æ˜¾ç¤ºä¿¡æ¯**ï¼š
- å½“å‰Epochè¿›åº¦ç™¾åˆ†æ¯”
- Batchç¼–å·
- å½“å‰Batchçš„Losså€¼ï¼ˆ6ä½å°æ•°ç²¾åº¦ï¼‰
- å½“å‰å­¦ä¹ ç‡ï¼ˆ8ä½å°æ•°ç²¾åº¦ï¼‰

### Epochç»“æŸæ—¶æ˜¾ç¤º

```
================================================================================
Epoch [15/200] å®Œæˆ
å¹³å‡æŸå¤±: 0.072316
æœ€å°BatchæŸå¤±: 0.065432
æœ€å¤§BatchæŸå¤±: 0.083571
å­¦ä¹ ç‡: 0.00100000
æœ¬epochç”¨æ—¶: 14.52ç§’
é¢„è®¡å‰©ä½™æ—¶é—´: 0.75å°æ—¶
================================================================================
```

**ç»Ÿè®¡ä¿¡æ¯**ï¼š
- è¯¥epochçš„å¹³å‡loss
- æœ€å°å’Œæœ€å¤§çš„batch lossï¼ˆäº†è§£è®­ç»ƒç¨³å®šæ€§ï¼‰
- å½“å‰å­¦ä¹ ç‡
- è®­ç»ƒæ—¶é—´å’ŒETAé¢„ä¼°

---

## äºŒã€è‡ªåŠ¨ä¿å­˜çš„æ•°æ®æ–‡ä»¶

### 1. Epochçº§åˆ«æŒ‡æ ‡ (epoch_metrics_*.csv)

**è‡ªåŠ¨ç”Ÿæˆ**ï¼Œæ¯ä¸ªepochä¸€è¡Œè®°å½•ï¼š

| Epoch | Avg_Loss | Min_Batch_Loss | Max_Batch_Loss | Learning_Rate | Epoch_Time_Seconds | Best_Loss_So_Far | Is_Best_Model | Timestamp |
|-------|----------|----------------|----------------|---------------|--------------------|--------------------|---------------|-----------|
| 1 | 0.425316 | 0.285432 | 0.623571 | 0.00100000 | 14.52 | 0.425316 | True | 2025-11-06 10:30:15 |
| 2 | 0.398245 | 0.268123 | 0.587234 | 0.00100000 | 14.38 | 0.398245 | True | 2025-11-06 10:30:30 |
| ... | ... | ... | ... | ... | ... | ... | ... | ... |

**ç”¨é€”**ï¼š
- ç»˜åˆ¶å®Œæ•´çš„è®­ç»ƒæ›²çº¿
- åˆ†ælossæ”¶æ•›è¶‹åŠ¿
- å¯¹æ¯”ä¸åŒè®­ç»ƒè¿è¡Œ
- å¯¼å‡ºåˆ°Excelè¿›è¡Œè‡ªå®šä¹‰åˆ†æ

### 2. Batchçº§åˆ«æŒ‡æ ‡ (batch_metrics_*.csv) - å¯é€‰

**éœ€è¦å‚æ•° `--log_batch_metrics` å¯ç”¨**ï¼Œæ¯ä¸ªbatchä¸€è¡Œï¼š

| Epoch | Batch | Loss | Learning_Rate | Timestamp |
|-------|-------|------|---------------|-----------|
| 1 | 0 | 0.523415 | 0.00100000 | 2025-11-06 10:30:15 |
| 1 | 1 | 0.498234 | 0.00100000 | 2025-11-06 10:30:16 |
| ... | ... | ... | ... | ... |

**ç”¨é€”**ï¼š
- è§‚å¯Ÿbatché—´çš„lossæ³¢åŠ¨
- è°ƒè¯•è®­ç»ƒä¸ç¨³å®šé—®é¢˜
- åˆ†æå­¦ä¹ ç‡è°ƒåº¦æ•ˆæœ
- ç ”ç©¶è¿‡æ‹Ÿåˆèµ·å§‹ç‚¹

---

## ä¸‰ã€ä½¿ç”¨æ–¹æ³•

### åŸºç¡€è®­ç»ƒï¼ˆæ¨èï¼‰

```bash
cd /workspace/GrayOcean/code/Medic_Project
python src/train_ddp.py
```

**é»˜è®¤è¡Œä¸º**ï¼š
- âœ… æ¯10ä¸ªbatchè¾“å‡ºä¸€æ¬¡è¿›åº¦
- âœ… è‡ªåŠ¨è®°å½•æ¯ä¸ªepochçš„ç»Ÿè®¡æ•°æ®
- âœ… ç”Ÿæˆ `metrics/epoch_metrics_YYYYMMDD_HHMMSS.csv`
- â±ï¸ æ•°æ®é‡ï¼š200 epochs = 200è¡Œï¼Œçº¦10-20KB

### è¯¦ç»†ç›‘æ§ï¼ˆå­¦ä¹ AIæ¨èï¼‰

```bash
python src/train_ddp.py --log_batch_metrics --log_interval 5
```

**å¢å¼ºè¡Œä¸º**ï¼š
- âœ… æ¯5ä¸ªbatchè¾“å‡ºä¸€æ¬¡ï¼ˆæ›´é¢‘ç¹ï¼‰
- âœ… è®°å½•æ¯ä¸ªepochçš„ç»Ÿè®¡æ•°æ®
- âœ… **é¢å¤–**è®°å½•æ¯ä¸ªbatchçš„è¯¦ç»†loss
- âœ… ç”Ÿæˆä¸¤ä¸ªæ–‡ä»¶ï¼š
  - `epoch_metrics_*.csv`
  - `batch_metrics_*.csv`
- â±ï¸ æ•°æ®é‡ï¼š200 epochs Ã— 171 batches â‰ˆ 34,200è¡Œï¼Œçº¦1-2MB

### å‚æ•°è¯´æ˜

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--log_interval` | 10 | æ¯Nä¸ªbatchè¾“å‡ºä¸€æ¬¡æ—¥å¿— |
| `--log_batch_metrics` | False | æ˜¯å¦è®°å½•æ¯ä¸ªbatchçš„è¯¦ç»†æ•°æ® |

**ç¤ºä¾‹**ï¼š

```bash
# æœ€å®‰é™æ¨¡å¼ï¼ˆæ¯100ä¸ªbatchè¾“å‡ºä¸€æ¬¡ï¼‰
python src/train_ddp.py --log_interval 100

# æœ€è¯¦ç»†æ¨¡å¼ï¼ˆæ¯ä¸ªbatchéƒ½è¾“å‡ºå’Œè®°å½•ï¼‰
python src/train_ddp.py --log_batch_metrics --log_interval 1

# å¹³è¡¡æ¨¡å¼ï¼ˆæ¯5ä¸ªbatchï¼Œä¸è®°å½•batchè¯¦æƒ…ï¼‰
python src/train_ddp.py --log_interval 5
```

---

## å››ã€è®­ç»ƒååˆ†æ

### 1. è‡ªåŠ¨åˆ†æï¼ˆä¸€é”®ç”ŸæˆæŠ¥å‘Šï¼‰

```bash
python analyze_training.py
```

**è‡ªåŠ¨ç”Ÿæˆ3ä¸ªæ–‡ä»¶**ï¼š

1. **training_analysis_*.png** - ç»¼åˆåˆ†æå›¾
   - Lossæ›²çº¿
   - Lossæ³¢åŠ¨èŒƒå›´
   - å­¦ä¹ ç‡å˜åŒ–
   - è®­ç»ƒæ—¶é—´ç»Ÿè®¡

2. **training_stats_*.png** - ç»Ÿè®¡åˆ†æå›¾
   - Lossæ”¹å–„è¶‹åŠ¿
   - è®­ç»ƒç¨³å®šæ€§åˆ†æ

3. **training_report_*.txt** - æ–‡æœ¬æŠ¥å‘Š
   - è®­ç»ƒæ¦‚è§ˆ
   - Lossç»Ÿè®¡
   - Top 5æœ€ä½³epochs

**æ–‡ä»¶ä½ç½®**ï¼š`analysis/` ç›®å½•

### 2. åˆ†æBatchæ•°æ®

```bash
python analyze_training.py --batch_metrics
```

ç”Ÿæˆbatchçº§åˆ«çš„è¯¦ç»†åˆ†æå›¾ã€‚

### 3. åˆ†æç‰¹å®šè®­ç»ƒ

```bash
python analyze_training.py --metrics_file metrics/epoch_metrics_20251106_103015.csv
```

---

## äº”ã€å®é™…ä½¿ç”¨ç¤ºä¾‹

### åœºæ™¯1ï¼šæ—¥å¸¸è®­ç»ƒï¼ˆæ¨èï¼‰

```bash
# å¯åŠ¨è®­ç»ƒ
python src/train_ddp.py

# è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä½ ä¼šå®æ—¶çœ‹åˆ°ï¼š
# Epoch [1/200] - è¿›åº¦ 5.8% (10/171) - Batch Loss: 0.425316 - LR: 0.00100000
# Epoch [1/200] - è¿›åº¦ 11.7% (20/171) - Batch Loss: 0.398245 - LR: 0.00100000
# ...
# ================================================================================
# Epoch [1/200] å®Œæˆ
# å¹³å‡æŸå¤±: 0.412534
# ...
# ================================================================================

# è®­ç»ƒå®Œæˆåç«‹å³åˆ†æ
python analyze_training.py
```

### åœºæ™¯2ï¼šè°ƒè¯•è®­ç»ƒä¸ç¨³å®š

```bash
# å¯ç”¨batchçº§åˆ«è®°å½•ï¼Œæ¯ä¸ªbatchéƒ½è¾“å‡º
python src/train_ddp.py --log_batch_metrics --log_interval 1

# è®­ç»ƒååˆ†æbatchæ³¢åŠ¨
python analyze_training.py --batch_metrics
```

### åœºæ™¯3ï¼šå¯¹æ¯”ä¸åŒé…ç½®

```bash
# è®­ç»ƒ1ï¼šå­¦ä¹ ç‡0.001
python src/train_ddp.py --lr 0.001
# ç”Ÿæˆï¼šmetrics/epoch_metrics_20251106_103015.csv

# è®­ç»ƒ2ï¼šå­¦ä¹ ç‡0.0001
python src/train_ddp.py --lr 0.0001
# ç”Ÿæˆï¼šmetrics/epoch_metrics_20251106_140520.csv

# ä½¿ç”¨Pythonè„šæœ¬å¯¹æ¯”
python
>>> import pandas as pd
>>> import matplotlib.pyplot as plt
>>> df1 = pd.read_csv('metrics/epoch_metrics_20251106_103015.csv')
>>> df2 = pd.read_csv('metrics/epoch_metrics_20251106_140520.csv')
>>> plt.plot(df1['Epoch'], df1['Avg_Loss'], label='LR=0.001')
>>> plt.plot(df2['Epoch'], df2['Avg_Loss'], label='LR=0.0001')
>>> plt.legend()
>>> plt.savefig('lr_comparison.png')
```

---

## å…­ã€æ–‡ä»¶ç»„ç»‡

### è®­ç»ƒè¿‡ç¨‹ä¸­ç”Ÿæˆ

```
Medic_Project/
â”œâ”€â”€ metrics/                                      # æ–°å¢ï¼šè®­ç»ƒæŒ‡æ ‡
â”‚   â”œâ”€â”€ epoch_metrics_20251106_103015.csv        # Epochç»Ÿè®¡
â”‚   â””â”€â”€ batch_metrics_20251106_103015.csv        # Batchè¯¦æƒ…ï¼ˆå¯é€‰ï¼‰
â”‚
â”œâ”€â”€ log/                                          # æ—¥å¿—æ–‡ä»¶
â”‚   â””â”€â”€ training_20251106_103015.log             # è¯¦ç»†æ—¥å¿—
â”‚
â””â”€â”€ checkpoints/                                  # æ¨¡å‹æ–‡ä»¶
    â”œâ”€â”€ model_epoch_10.pth
    â”œâ”€â”€ model_epoch_20.pth
    â””â”€â”€ best_model.pth
```

### åˆ†æåç”Ÿæˆ

```
Medic_Project/
â””â”€â”€ analysis/                                     # æ–°å¢ï¼šåˆ†æç»“æœ
    â”œâ”€â”€ training_analysis_epoch_metrics_20251106_103015.png
    â”œâ”€â”€ training_stats_epoch_metrics_20251106_103015.png
    â””â”€â”€ training_report_epoch_metrics_20251106_103015.txt
```

---

## ä¸ƒã€å­¦ä¹ AIçš„æœ€ä½³å®è·µ

### ç¬¬ä¸€æ¬¡è®­ç»ƒ

```bash
# ä½¿ç”¨é»˜è®¤è®¾ç½®
python src/train_ddp.py --epochs 10  # å…ˆè®­ç»ƒ10ä¸ªepochçœ‹çœ‹

# ç«‹å³åˆ†æ
python analyze_training.py
```

æŸ¥çœ‹ç”Ÿæˆçš„å›¾è¡¨ï¼Œé‡ç‚¹å…³æ³¨ï¼š
1. Lossæ˜¯å¦ä¸‹é™
2. Lossæ³¢åŠ¨æ˜¯å¦è¿‡å¤§
3. è®­ç»ƒæ—¶é—´æ˜¯å¦åˆç†

### æ­£å¼è®­ç»ƒ

```bash
# å¯ç”¨batchè®°å½•ï¼Œä¾¿äºå­¦ä¹ 
python src/train_ddp.py --log_batch_metrics --log_interval 5

# è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå¦å¼€ä¸€ä¸ªç»ˆç«¯å®æ—¶æŸ¥çœ‹
tail -f log/training_*.log

# æˆ–è€…æŸ¥çœ‹metricsæ–‡ä»¶
tail -f metrics/epoch_metrics_*.csv
```

### å¤ç›˜å­¦ä¹ 

è®­ç»ƒå®Œæˆåï¼š

```bash
# ç”Ÿæˆåˆ†ææŠ¥å‘Š
python analyze_training.py

# æŸ¥çœ‹å›¾è¡¨
cd analysis
ls -lh  # æŸ¥çœ‹ç”Ÿæˆçš„PNGæ–‡ä»¶

# æŸ¥çœ‹æ–‡æœ¬æŠ¥å‘Š
cat training_report_*.txt
```

**é‡ç‚¹å­¦ä¹ å†…å®¹**ï¼š
1. **Lossæ›²çº¿**ï¼šäº†è§£æ”¶æ•›è¿‡ç¨‹
2. **Lossæ³¢åŠ¨**ï¼šç†è§£è®­ç»ƒç¨³å®šæ€§
3. **å­¦ä¹ ç‡å½±å“**ï¼šè§‚å¯ŸLRå¯¹è®­ç»ƒçš„å½±å“
4. **æœ€ä½³æ¨¡å‹**ï¼šå“ªä¸ªepochæ•ˆæœæœ€å¥½

---

## å…«ã€ å¸¸è§é—®é¢˜

### Q: è¿™ä¼šè®©è®­ç»ƒå˜æ…¢å—ï¼Ÿ

A: **å‡ ä¹ä¸ä¼š**ã€‚
- æ–‡ä»¶IOæ“ä½œéå¸¸å¿«ï¼ˆæ¯10ä¸ªbatchå†™ä¸€æ¬¡ï¼‰
- Batchè®°å½•æ¨¡å¼ä¼šå¢åŠ <1%çš„æ—¶é—´å¼€é”€
- ä¸»è¦ç“¶é¢ˆä»ç„¶æ˜¯GPUè®¡ç®—

### Q: æ•°æ®æ–‡ä»¶ä¼šå¾ˆå¤§å—ï¼Ÿ

A: **ä¸ä¼š**ã€‚
- Epochçº§åˆ«ï¼š200 epochs â‰ˆ 10-20KB
- Batchçº§åˆ«ï¼š34,000 rows â‰ˆ 1-2MB
- éƒ½æ˜¯çº¯æ–‡æœ¬CSVï¼Œå‹ç¼©åæ›´å°

### Q: æˆ‘èƒ½åœ¨è®­ç»ƒæ—¶æŸ¥çœ‹metricsæ–‡ä»¶å—ï¼Ÿ

A: **å¯ä»¥**ã€‚æ–‡ä»¶æ˜¯å®æ—¶å†™å…¥çš„ï¼š

```bash
# å®æ—¶æŸ¥çœ‹æœ€æ–°çš„å‡ è¡Œ
tail -f metrics/epoch_metrics_*.csv

# æˆ–ç”¨Pythonè„šæœ¬å®æ—¶è¯»å–
watch -n 5 'tail -3 metrics/epoch_metrics_*.csv'
```

### Q: å¦‚ä½•åˆ é™¤æ—§çš„metricsï¼Ÿ

A:
```bash
# åªä¿ç•™æœ€è¿‘7å¤©çš„
find metrics/ -name "*.csv" -mtime +7 -delete

# æˆ–æ‰‹åŠ¨åˆ é™¤
rm metrics/epoch_metrics_OLD_TIMESTAMP.csv
```

---

## ä¹ã€è¿›é˜¶æŠ€å·§

### 1. åœ¨Jupyter Notebookä¸­å®æ—¶ç›‘æ§

```python
import pandas as pd
import matplotlib.pyplot as plt
from IPython.display import clear_output
import time

def live_monitor(metrics_file, interval=10):
    """å®æ—¶ç›‘æ§è®­ç»ƒè¿›åº¦"""
    plt.figure(figsize=(10, 5))

    while True:
        try:
            df = pd.read_csv(metrics_file)

            clear_output(wait=True)

            # ç»˜åˆ¶lossæ›²çº¿
            plt.subplot(1, 2, 1)
            plt.cla()
            plt.plot(df['Epoch'], df['Avg_Loss'], 'b-')
            plt.xlabel('Epoch')
            plt.ylabel('Loss')
            plt.title('Training Loss (Live)')
            plt.grid(True)

            # æ˜¾ç¤ºæœ€æ–°ä¿¡æ¯
            plt.subplot(1, 2, 2)
            plt.cla()
            plt.axis('off')
            latest = df.iloc[-1]
            info = f"""
            Latest Epoch: {latest['Epoch']}
            Avg Loss: {latest['Avg_Loss']:.6f}
            Best Loss: {latest['Best_Loss_So_Far']:.6f}
            Learning Rate: {latest['Learning_Rate']:.8f}
            """
            plt.text(0.1, 0.5, info, fontsize=14, family='monospace')

            plt.tight_layout()
            plt.show()

            time.sleep(interval)

        except KeyboardInterrupt:
            break

# ä½¿ç”¨
live_monitor('metrics/epoch_metrics_20251106_103015.csv')
```

### 2. å¯¼å‡ºç»™å…¶ä»–å·¥å…·

```python
# è½¬æ¢ä¸ºJSON
import pandas as pd
import json

df = pd.read_csv('metrics/epoch_metrics_*.csv')
df.to_json('training_metrics.json', orient='records', indent=2)

# è½¬æ¢ä¸ºExcel
df.to_excel('training_metrics.xlsx', index=False)
```

---

## åã€æ€»ç»“

### æ–°åŠŸèƒ½æ¸…å•

âœ… **å®æ—¶ç›‘æ§**
  - å¯é…ç½®çš„æ—¥å¿—è¾“å‡ºé¢‘ç‡
  - Batchçº§åˆ«çš„lossæ˜¾ç¤º
  - å­¦ä¹ ç‡å®æ—¶æ˜¾ç¤º
  - ETAé¢„ä¼°

âœ… **æ•°æ®è®°å½•**
  - Epochçº§åˆ«CSVï¼ˆè‡ªåŠ¨ï¼‰
  - Batchçº§åˆ«CSVï¼ˆå¯é€‰ï¼‰
  - æ—¶é—´æˆ³æ–‡ä»¶åï¼ˆä¸è¦†ç›–ï¼‰

âœ… **äº‹ååˆ†æ**
  - è‡ªåŠ¨ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
  - æ–‡æœ¬åˆ†ææŠ¥å‘Š
  - æ”¯æŒè‡ªå®šä¹‰åˆ†æ

âœ… **çµæ´»é…ç½®**
  - `--log_interval`: æ§åˆ¶è¾“å‡ºé¢‘ç‡
  - `--log_batch_metrics`: å¯ç”¨è¯¦ç»†è®°å½•

### æ¨èå·¥ä½œæµç¨‹

1. **å¼€å§‹è®­ç»ƒ**
   ```bash
   python src/train_ddp.py --log_interval 10
   ```

2. **å®æ—¶ç›‘æ§**ï¼ˆå¯é€‰ï¼‰
   ```bash
   # å¦å¼€ç»ˆç«¯
   tail -f log/training_*.log
   ```

3. **è®­ç»ƒå®Œæˆåç«‹å³åˆ†æ**
   ```bash
   python analyze_training.py
   ```

4. **æŸ¥çœ‹ç»“æœ**
   ```bash
   cd analysis
   ls -lh  # æŸ¥çœ‹ç”Ÿæˆçš„æ–‡ä»¶
   ```

---

## ç›¸å…³æ–‡æ¡£

- **è¯¦ç»†ä½¿ç”¨æŒ‡å—**: `METRICS_GUIDE.md`
- **æ—¥å¿—ç³»ç»ŸæŠ¥å‘Š**: `LOGGING_REPORT.md`

---

**ç¥ä½ å­¦ä¹ æ„‰å¿«ï¼ğŸ“**


## [-> è¿”å›README](../README.md)

